#!/usr/bin/env python3
"""
Gramps Benchmark All Script

This script runs performance benchmarks across multiple Gramps versions and generates
comparative charts. It can be called from the command line with various options.

Usage:
    python gramps_bench_all.py <gramps_file> <gramps_source_dir> [options]
    python gramps_bench_all.py --help
"""

import argparse
import os
import subprocess
import sys
from pathlib import Path

# Import the gramps_bench functions
from gramps_bench import gramps_benchmark
from gramps_bench import main as run_benchmark


def run_git_checkout(gramps_source_dir, version):
    """Run git checkout for a specific version."""
    try:
        subprocess.run(
            ["git", "checkout", "-f", version],
            cwd=gramps_source_dir,
            capture_output=True,
            text=True,
            check=True,
        )
        print(f"‚úÖ Checked out version {version}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Failed to checkout version {version}: {e}")
        print(f"Git output: {e.stderr}")
        return False


def run_benchmarks_for_version(gramps_file, output_dir, version=None):
    """Run benchmarks for a specific version."""
    print(f"\nüöÄ Running benchmarks for version: {version or 'current'}")
    print("=" * 60)

    # Set up arguments for the benchmark function
    sys.argv = ["gramps_bench", gramps_file, "--output", output_dir]

    if version:
        sys.argv.extend(["--version", version])

    try:
        # Run the benchmark
        run_benchmark()
        return True
    except Exception as e:
        print(f"‚ùå Benchmark failed for version {version}: {e}")
        return False


def generate_final_charts(output_dir, format="pdf"):
    """Generate final comparative charts."""
    format_name = "HTML pages" if format == "html" else "PDFs"
    print(f"\nüìä Generating final comparative {format_name}...")
    print("=" * 60)

    try:
        success = gramps_benchmark(output_dir=output_dir, format=format)
        if success:
            print("‚úÖ Chart generation completed successfully!")
            return True
        else:
            print("‚ùå Chart generation failed")
            return False
    except Exception as e:
        print(f"‚ùå Error generating charts: {e}")
        return False


def open_output_files(output_dir, format="pdf"):
    """Open generated output files with the default viewer."""
    try:
        if format == "html":
            # Open HTML files with default browser
            html_files = list(Path(output_dir).glob("*.html"))
            if html_files:
                print(f"\nüåê Opening {len(html_files)} HTML file(s)...")
                for html_file in html_files:
                    subprocess.Popen(["xdg-open", str(html_file)])
                return True
            else:
                print("No HTML files found to open")
                return False
        else:
            # Open PDF files with default PDF viewer
            pdf_files = list(Path(output_dir).glob("*.pdf"))
            if pdf_files:
                print(f"\nüìÑ Opening {len(pdf_files)} PDF file(s)...")
                for pdf_file in pdf_files:
                    subprocess.Popen(["evince", str(pdf_file)])
                return True
            else:
                print("No PDF files found to open")
                return False
    except Exception as e:
        print(f"‚ùå Error opening {format} files: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(
        description="Run Gramps performance benchmarks across multiple versions",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python gramps_bench_all.py /path/to/gramps_file.gramps /path/to/gramps/source
  python gramps_bench_all.py data.gramps /home/user/gramps --versions v5.1.6 v5.2.4
  python gramps_bench_all.py data.gramps /home/user/gramps --output /tmp/results --open
        """,
    )

    parser.add_argument("gramps_file", help="Path to the Gramps database file to test")

    parser.add_argument(
        "gramps_source_dir",
        help="Path to the Gramps source directory (for git checkout)",
    )

    parser.add_argument(
        "--output",
        "-o",
        default=os.getcwd(),
        help="Output directory for benchmark results (default: current directory)",
    )

    parser.add_argument(
        "--versions",
        nargs="+",
        default=["v5.1.6", "v5.2.4", "v6.0.4"],
        help="List of Git versions to test (default: v5.1.6 v5.2.4 v6.0.4)",
    )

    parser.add_argument(
        "--open",
        action="store_true",
        help="Automatically open output files after generation",
    )

    parser.add_argument(
        "--skip-charts",
        action="store_true",
        help="Skip generating final comparative charts",
    )

    parser.add_argument(
        "--format",
        choices=["pdf", "html"],
        default="pdf",
        help="Output format for charts (pdf or html, default: pdf)",
    )

    args = parser.parse_args()

    # Validate inputs
    if not os.path.exists(args.gramps_file):
        print(f"‚ùå Error: Gramps file not found: {args.gramps_file}")
        sys.exit(1)

    if not os.path.exists(args.gramps_source_dir):
        print(f"‚ùå Error: Gramps source directory not found: {args.gramps_source_dir}")
        sys.exit(1)

    # Check if it's a git repository
    git_dir = os.path.join(args.gramps_source_dir, ".git")
    if not os.path.exists(git_dir):
        print(f"‚ùå Error: {args.gramps_source_dir} is not a git repository")
        sys.exit(1)

    # Create output directory if it doesn't exist
    os.makedirs(args.output, exist_ok=True)

    # Clean up previous benchmark results
    benchmark_dir = os.path.join(args.output, ".benchmarks")
    if os.path.exists(benchmark_dir):
        print("üßπ Cleaning up previous benchmark results...")
        import shutil

        shutil.rmtree(benchmark_dir)

    print("üéØ Starting Gramps performance benchmarks")
    print(f"üìÅ Gramps file: {args.gramps_file}")
    print(f"üìÅ Source directory: {args.gramps_source_dir}")
    print(f"üìÅ Output directory: {args.output}")
    print(f"üî¢ Versions to test: {', '.join(args.versions)}")
    print("=" * 60)

    # Store original working directory
    original_cwd = os.getcwd()

    try:
        # Change to gramps source directory
        os.chdir(args.gramps_source_dir)

        # Run benchmarks for each version
        for version in args.versions:
            print(f"\nüîÑ Processing version: {version}")

            # Checkout the version
            if not run_git_checkout(args.gramps_source_dir, version):
                print(f"‚ö†Ô∏è  Skipping version {version} due to checkout failure")
                continue

            # Run benchmarks for this version
            if not run_benchmarks_for_version(args.gramps_file, args.output, version):
                print(f"‚ö†Ô∏è  Skipping version {version} due to benchmark failure")
                continue

        # Run final benchmark without version override (current version)
        print("\nüîÑ Processing current version")
        if not run_benchmarks_for_version(args.gramps_file, args.output):
            print("‚ö†Ô∏è  Final benchmark failed")

        # Generate comparative charts
        if not args.skip_charts:
            if not generate_final_charts(args.output, args.format):
                print("‚ö†Ô∏è  Chart generation failed")

        # Open output files
        if args.open:
            open_output_files(args.output, args.format)

        print("\n‚úÖ All benchmarks completed successfully!")
        print(f"üìÅ Results saved in: {args.output}")

    except KeyboardInterrupt:
        print("\n‚èπÔ∏è  Benchmarks interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Error during benchmarks: {e}")
        sys.exit(1)
    finally:
        # Restore original working directory
        os.chdir(original_cwd)


if __name__ == "__main__":
    main()
